{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import re\n",
    "from pyfaidx import Fasta\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNP Enrichment\n",
    "## Binomial Test\n",
    "# def snp_enrich(vcf, cpg_bed, reference):\n",
    "#     # Read in the VCF file\n",
    "#     vcf = pd.read_csv(vcf,\n",
    "#                     sep='\\t',\n",
    "#                     comment='#',\n",
    "#                     names=['CHROM','POS','ID','REF','ALT',\n",
    "#             'QUAL','FILTER','INFO','FORMAT',\n",
    "#             'sample'])\n",
    "\n",
    "#     # Keep only the SNPs, i.e. single bases in REF and ALT\n",
    "#     vcf = vcf[(vcf['ALT'].str.len() == 1) & (vcf['REF'].str.len() == 1)]\n",
    "\n",
    "#     cpgs = pd.read_csv(cpg_bed,\n",
    "#                     sep='\\t',\n",
    "#                     names=['Chrom','Start','Stop','ID','Score','Strand'])\n",
    "\n",
    "#     # Minimap2 identified a mutation at position 149,470 = G to A.\n",
    "#     # There is a CpG site at position 149,468 to 149,470.\n",
    "#     # Therefore, add 1 to the start position of the CpG site to find SNPs affecting\n",
    "#     # the C and use the stop position to find SNPs affecting the G.\n",
    "#     cpgs['C'] = cpgs['Start'] + 1\n",
    "#     cpgs['G'] = cpgs['Stop']\n",
    "\n",
    "#     vcf['SNP_hit_C'] = vcf['POS'].isin(cpgs['C'])\n",
    "#     vcf['SNP_hit_G'] = vcf['POS'].isin(cpgs['G'])\n",
    "#     vcf['DoubleCount'] = vcf['SNP_hit_C'] & vcf['SNP_hit_G']\n",
    "\n",
    "#     # Get total number of SNPs before removing double counted SNPs\n",
    "#     total_snps = vcf.shape[0]\n",
    "\n",
    "#     # Drop the double counted SNPs\n",
    "#     vcf = vcf[vcf['DoubleCount'] == False]\n",
    "\n",
    "#     snp_prob = (total_snps / len(reference))\n",
    "#     snps_hit_cpg = (vcf['SNP_hit_C'].sum() + vcf['SNP_hit_G'].sum())\n",
    "\n",
    "\n",
    "#     # k = number of successes, E.g. number of SNPs that hit a CpG site.\n",
    "#     # n = number of trials, E.g. number of SNPs.\n",
    "#     # p = probability of success, E.g. probability of a SNP occurring anywhere.\n",
    "\n",
    "#     k = snps_hit_cpg\n",
    "#     n = total_snps\n",
    "#     p = snp_prob\n",
    "\n",
    "#     test = stats.binomtest(k = k, n = n, p = p, alternative='greater')\n",
    "\n",
    "#     #return test.statistic, test.pvalue\n",
    "#     return snps_hit_cpg, total_snps, len(reference)\n",
    "\n",
    "#def snp_enrichment_freq(vcf, cpg_bed, reference):\n",
    "\n",
    "# Create a dictionary to store the contingency table\n",
    "# For each base, is it:\n",
    "# 1. A SNP in a CpG site\n",
    "# 2. A SNP not in a CpG site\n",
    "# 3. Not a SNP in a CpG site\n",
    "# 4. Not a SNP not in a CpG site\n",
    "# contingency_table = {\n",
    "#     'base_hit_snp_cpg'        :0,\n",
    "#     'base_hit_snp_not_cpg'    :0,\n",
    "#     'base_hit_cpg_not_snp'    :0,\n",
    "#     'base_hit_not_cpg_not_snp':0\n",
    "#     }\n",
    "def chiSquare_SNPs(chrom, VCF, CPG_BED, REFERENCE):\n",
    "    \n",
    "    # Read in the VCF file\n",
    "    vcf = pd.read_csv(VCF,\n",
    "            sep='\\t',\n",
    "            comment='#',\n",
    "            names=['CHROM','POS','ID','REF','ALT',\n",
    "    'QUAL','FILTER','INFO','FORMAT',\n",
    "    'sample'])\n",
    "\n",
    "    # Keep only the SNPs, i.e. single bases in REF and ALT\n",
    "    vcf = vcf[(vcf['ALT'].str.len() == 1) & (vcf['REF'].str.len() == 1)]\n",
    "\n",
    "    # Read in CpG bed file\n",
    "    cpgs = pd.read_csv(CPG_BED,\n",
    "                sep='\\t',\n",
    "                names=['Chrom','Start','Stop','ID','Score','Strand'])\n",
    "\n",
    "    # Minimap2 identified a mutation at position 149,470 = G to A.\n",
    "    # There is a CpG site at position 149,468 to 149,470.\n",
    "    # Therefore, add 1 to the start position of the CpG site to find SNPs affecting\n",
    "    # the C and use the stop position to find SNPs affecting the G.\n",
    "    cpgs['C'] = cpgs['Start'] + 1\n",
    "    cpgs['G'] = cpgs['Stop']\n",
    "\n",
    "    vcf['SNP_hit_C'] = vcf['POS'].isin(cpgs['C'])\n",
    "    vcf['SNP_hit_G'] = vcf['POS'].isin(cpgs['G'])\n",
    "    vcf['DoubleCount'] = vcf['SNP_hit_C'] & vcf['SNP_hit_G']\n",
    "\n",
    "    # Drop the double counted SNPs\n",
    "    vcf = vcf[vcf['DoubleCount'] == False]\n",
    "\n",
    "    cpgs_snps = {}    # SNPs that hit a CpG site\n",
    "    non_cpg_snps = {} # SNPs that do not hit a CpG site\n",
    "\n",
    "    for row in vcf.itertuples():\n",
    "        if row.SNP_hit_C == True or row.SNP_hit_G == True:\n",
    "            chrpos = str(row.CHROM) + '_' + str(row.POS)\n",
    "            cpgs_snps[chrpos] = None\n",
    "        else:\n",
    "            chrpos = str(row.CHROM) + '_' + str(row.POS)\n",
    "            non_cpg_snps[chrpos] = None\n",
    "\n",
    "    chrom_seq = REFERENCE[str(chrom)]\n",
    "\n",
    "    is_cpg = []\n",
    "    is_snp = []\n",
    "\n",
    "\n",
    "    unaffected_cpgs = cpgs.shape[0] - len(cpgs_snps.keys())\n",
    "    unaffected_cpgs_bases = unaffected_cpgs * 2\n",
    "    affected_cpgs_bases = len(cpgs_snps.keys()) * 2\n",
    "    non_cpgs_snps = len(non_cpg_snps.keys())\n",
    "    remaining_bases = len(chrom_seq) - (unaffected_cpgs_bases + affected_cpgs_bases + non_cpgs_snps)\n",
    "\n",
    "    # Add the is_cpg and is_snp labels to the list\n",
    "    is_cpg.extend(['is_cpg'] * affected_cpgs_bases)\n",
    "    is_snp.extend(['is_snp'] * affected_cpgs_bases)\n",
    "\n",
    "    is_cpg.extend(['not_cpg'] * non_cpgs_snps)\n",
    "    is_snp.extend(['is_snp'] * non_cpgs_snps)\n",
    "\n",
    "    is_cpg.extend(['is_cpg'] * unaffected_cpgs_bases)\n",
    "    is_snp.extend(['not_snp'] * unaffected_cpgs_bases)\n",
    "\n",
    "    is_cpg.extend(['not_cpg'] * remaining_bases)\n",
    "    is_snp.extend(['not_snp'] * remaining_bases)\n",
    "\n",
    "    contingency_table = pd.DataFrame({'is_cpg':is_cpg, 'is_snp':is_snp})\n",
    "    x = pd.crosstab(contingency_table['is_cpg'], contingency_table['is_snp'])\n",
    "    x.to_csv(f'snp_fisherexact/{chrom}_contingency_table.csv', header=True, index=True)\n",
    "    # print(x.values)\n",
    "\n",
    "    _stat, _pval = chi2_contingency(x.values)[:2]\n",
    "    \n",
    "    return _stat, _pval\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [08:27<00:00, 17.49s/it]\n"
     ]
    }
   ],
   "source": [
    "stats_ = []\n",
    "pvals_ = []\n",
    "\n",
    "REFERENCE = Fasta('/Users/callummacphillamy/PhD/methylation_chapter/'\n",
    "                      'gigascience_revisions/references/brahman/Brahman.fa')\n",
    "\n",
    "for chrom in tqdm(range(1, 30)):\n",
    "    VCF = f'./brahman/vcf/brahman_{chrom}_vs_angus_{chrom}.vcf.gz'\n",
    "    CPG_BED = ('/Users/callummacphillamy/PhD/methylation_chapter/'\n",
    "               'gigascience_revisions/Brah-Ang_methylation/genome/Brahman_CpG/'\n",
    "               f'beds/Brahman_{chrom}.CpGs.bed.gz')\n",
    "    \n",
    "    stat_, pval_, = chiSquare_SNPs(chrom, VCF, CPG_BED, REFERENCE)\n",
    "    stats_.append(stat_)\n",
    "    pvals_.append(pval_)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 0.0017671710005495722,\n",
       " 0.001724137931034483)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform multiple testing correction\n",
    "pvals_ = np.array(pvals_)\n",
    "multipletests(pvals_, method='fdr_bh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 857.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold enrichment: 12.953283537771606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine fold enrichment for CpG SNPs vs non-CpG SNPs\n",
    "is_snp_is_cpg = 0 # A\n",
    "is_snp_not_cpg = 0 # B\n",
    "not_snp_is_cpg = 0 # C\n",
    "not_snp_not_cpg = 0 # D\n",
    "\n",
    "for i in tqdm(range(1,30)):\n",
    "    cont_table = pd.read_csv(f'snp_chi/{i}_contingency_table.csv', index_col=0)\n",
    "    is_snp_is_cpg += cont_table.loc['is_cpg', 'is_snp']\n",
    "    is_snp_not_cpg += cont_table.loc['not_cpg', 'is_snp']\n",
    "    not_snp_is_cpg += cont_table.loc['is_cpg', 'not_snp']\n",
    "    not_snp_not_cpg += cont_table.loc['not_cpg', 'not_snp']\n",
    "A_in_cat_of_interest = is_snp_is_cpg\n",
    "total_cat_of_interest = is_snp_is_cpg + is_snp_not_cpg\n",
    "B_in_background = not_snp_is_cpg\n",
    "total_background = not_snp_is_cpg + not_snp_not_cpg\n",
    "print('fold enrichment:', (A_in_cat_of_interest / total_cat_of_interest) / (B_in_background / total_background))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SV CpG Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "791895it [00:00, 994064.96it/s] \n",
      "681471it [00:00, 1000502.14it/s]\n",
      "568905it [00:00, 945398.59it/s]\n",
      "597400it [00:00, 1020763.86it/s]\n",
      "543304it [00:00, 949149.68it/s]\n",
      "606340it [00:00, 972080.42it/s]\n",
      "567375it [00:00, 972804.81it/s]\n",
      "518721it [00:00, 972196.01it/s]\n",
      "532052it [00:00, 971289.79it/s]\n",
      "537562it [00:00, 1013653.76it/s]\n",
      "496830it [00:00, 1004110.71it/s]\n",
      "418196it [00:00, 988201.11it/s]\n",
      "360277it [00:00, 1008743.76it/s]\n",
      "401396it [00:00, 1002322.98it/s]\n",
      "473250it [00:00, 1009122.15it/s]\n",
      "397779it [00:00, 1000223.65it/s]\n",
      "358587it [00:00, 986152.69it/s]\n",
      "250576it [00:00, 977988.05it/s]\n",
      "325654it [00:00, 980055.70it/s]\n",
      "240723it [00:00, 939743.80it/s]\n",
      "363936it [00:00, 946057.57it/s]\n",
      "298564it [00:00, 982746.12it/s]\n",
      "299415it [00:00, 963904.57it/s]\n",
      "367108it [00:00, 1009346.12it/s]\n",
      "181793it [00:00, 977823.60it/s]\n",
      "235475it [00:00, 991152.50it/s]\n",
      "280249it [00:00, 988089.88it/s]\n",
      "179962it [00:00, 990823.56it/s]\n",
      "299971it [00:00, 1005665.15it/s]\n"
     ]
    }
   ],
   "source": [
    "b_small_indels = []\n",
    "b_svs = {}\n",
    "b_sv_coords = {'chrom':[],\n",
    "\t\t\t   'start':[],\n",
    "\t\t\t   'stop':[]}\n",
    "b_sv_len = {}\n",
    "\n",
    "a_small_indels = []\n",
    "a_svs = {}\n",
    "a_sv_coords = {'chrom':[],\n",
    "\t\t\t   'start':[],\n",
    "\t\t\t   'stop':[]}\n",
    "a_sv_len = {}\n",
    "\n",
    "# As these are structural variants and indels greater than 1 bp in length, we\n",
    "# can just count the occurrences of a CpG site in the sequence of each variant\n",
    "for chrom in range(1,30):\n",
    "\tvcf = pd.read_csv(f'./brahman/vcf/brahman_{chrom}_vs_angus_{chrom}.vcf.gz',\n",
    "\t\t\t\t  sep='\\t',\n",
    "\t\t\t\t  comment='#',\n",
    "\t\t\t\t  names=['CHROM','POS','ID','REF','ALT',\n",
    "\t\t   'QUAL','FILTER','INFO','FORMAT',\n",
    "\t\t   'sample'])\n",
    "\ta_svs[str(chrom)] = 0\n",
    "\tb_svs[str(chrom)] = 0\n",
    "\ta_sv_len[str(chrom)] = 0\n",
    "\tb_sv_len[str(chrom)] = 0\n",
    "\tfor record in tqdm(vcf.itertuples()):\n",
    "\t\tif len(record.REF) == 1 and len(record.ALT) == 1:\n",
    "\t\t\tcontinue\n",
    "\t\tinfo = record.INFO.split(';')\n",
    "\t\tq_start = int(info[1].split('=')[1])\n",
    "\t\tif len(record.REF) <= 50 and len(record.ALT) <= 50:\n",
    "\t\t\tb_small_indels.append(len(re.findall('CG', record.REF))) \n",
    "\t\t\ta_small_indels.append(len(re.findall('CG', record.ALT)))\n",
    "\t\telif len(record.REF) <= 50 and len(record.ALT) > 50:\n",
    "\t\t\tb_small_indels.append(len(re.findall('CG', record.REF)))\n",
    "\t\t\t#a_svs.append(len(re.findall('CG', record.ALT)))\n",
    "\t\t\ta_svs[str(record.CHROM)] += len(re.findall('CG', record.ALT))\n",
    "\t\t\ta_sv_len[str(record.CHROM)] += len(record.ALT)\n",
    "\t\t\ta_sv_coords['chrom'].append(record.CHROM)\n",
    "\t\t\ta_sv_coords['start'].append(q_start - 2)\n",
    "\t\t\ta_sv_coords['stop'].append(q_start - 2 + len(record.ALT))\n",
    "\t\telif len(record.REF) > 50 and len(record.ALT) <= 50:\n",
    "\t\t\t#b_svs.append(len(re.findall('CG', record.REF)))\n",
    "\t\t\tb_svs[str(record.CHROM)] += len(re.findall('CG', record.REF))\n",
    "\t\t\tb_sv_len[str(record.CHROM)] += len(record.REF)\n",
    "\t\t\tb_sv_coords['chrom'].append(record.CHROM)\n",
    "\t\t\tb_sv_coords['start'].append(record.POS - 1)\n",
    "\t\t\tb_sv_coords['stop'].append(record.POS - 1 + len(record.REF))\n",
    "\t\t\ta_small_indels.append(len(re.findall('CG', record.ALT)))\n",
    "\t\telif len(record.REF) > 50 and len(record.ALT) > 50:\n",
    "\t\t\t#b_svs.append(len(re.findall('CG', record.REF)))\n",
    "\t\t\tb_svs[str(record.CHROM)] += len(re.findall('CG', record.REF))\n",
    "\t\t\tb_sv_coords['chrom'].append(record.CHROM)\n",
    "\t\t\tb_sv_coords['start'].append(record.POS - 1)\n",
    "\t\t\tb_sv_coords['stop'].append(record.POS - 1 + len(record.REF))\n",
    "\t\t\tb_sv_len[str(record.CHROM)] += len(record.REF)\n",
    "\t\t\t\n",
    "\t\t\t#a_svs.append(len(re.findall('CG', record.ALT)))\n",
    "\t\t\ta_svs[str(record.CHROM)] += len(re.findall('CG', record.ALT))\n",
    "\t\t\ta_sv_coords['chrom'].append(record.CHROM)\n",
    "\t\t\ta_sv_coords['start'].append(q_start - 2)\n",
    "\t\t\ta_sv_coords['stop'].append(q_start - 2 + len(record.ALT))\n",
    "\t\t\ta_sv_len[str(record.CHROM)] += len(record.ALT)\n",
    "\t\telse:\n",
    "\t\t\tprint('Something unforeseen happened.')\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CpGs in Brahman small indels: 29668\n",
      "CpGs in Brahman SVs: {'1': 10085, '2': 7778, '3': 8112, '4': 7526, '5': 9504, '6': 8265, '7': 8307, '8': 9096, '9': 10847, '10': 7756, '11': 5571, '12': 4911, '13': 5518, '14': 4503, '15': 9186, '16': 5615, '17': 5191, '18': 6763, '19': 5980, '20': 3857, '21': 6151, '22': 3360, '23': 7257, '24': 6322, '25': 2466, '26': 3708, '27': 4733, '28': 2276, '29': 4746}\n",
      "CpGs in Angus small indels: 29452\n",
      "CpGs in Angus SVs: {'1': 11296, '2': 7837, '3': 8267, '4': 9580, '5': 8336, '6': 9466, '7': 8629, '8': 9635, '9': 7190, '10': 7315, '11': 5179, '12': 7021, '13': 4067, '14': 4858, '15': 7089, '16': 4539, '17': 5109, '18': 4262, '19': 3982, '20': 4386, '21': 4877, '22': 2872, '23': 6793, '24': 4945, '25': 2048, '26': 3637, '27': 4604, '28': 2421, '29': 6097}\n"
     ]
    }
   ],
   "source": [
    "print(f'CpGs in Brahman small indels: {np.sum(b_small_indels)}')\n",
    "print(f'CpGs in Brahman SVs: {np.sum(b_svs)}')\n",
    "print(f'CpGs in Angus small indels: {np.sum(a_small_indels)}')\n",
    "print(f'CpGs in Angus SVs: {np.sum(a_svs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the coordinates of the SVs\n",
    "pd.DataFrame.from_dict(a_sv_coords).sort_values(by=['chrom','start']).to_csv('angus_SV_coords.bed', sep='\\t', index=False, header=False)\n",
    "pd.DataFrame.from_dict(b_sv_coords).sort_values(by=['chrom','start']).to_csv('brahman_SV_coords.bed', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "## SHELL SCRIPT\n",
    "# Get the complement of the SV regions\n",
    "bedtools complement -i angus_SV_coords.bed -g Angus.chrom.sizes > angus_non_SV_coords.bed\n",
    "bedtools complement -i brahman_SV_coords.bed -g Brahman.chrom.sizes > brahman_non_SV_coords.bed\n",
    "\n",
    "# Get the fasta sequences of the complement regions\n",
    "bedtools getfasta -fi /Users/callummacphillamy/PhD/gigascience_revisions/references/angus/Angus.fa -bed angus_non_SV_coords.bed -fo angus_non_SV_seq.fa\n",
    "\n",
    "bedtools getfasta -fi /Users/callummacphillamy/PhD/gigascience_revisions/references/brahman/Brahman.fa -bed brahman_non_SV_coords.bed -fo brahman_non_SV_seq.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Brahman non-SV fasta file\n",
    "brahman_non_SV = SeqIO.to_dict(SeqIO.parse('./brahman_non_SV_seq.fa', 'fasta'))\n",
    "\n",
    "# Load the Angus non-SV fasta file\n",
    "angus_non_SV = SeqIO.to_dict(SeqIO.parse('./angus_non_SV_seq.fa', 'fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16040/16040 [00:04<00:00, 3438.46it/s]\n",
      "100%|██████████| 15500/15500 [00:04<00:00, 3343.19it/s]\n"
     ]
    }
   ],
   "source": [
    "brahman_non_SV_cpgs = {}\n",
    "brahman_non_sv_len = {}\n",
    "angus_non_SV_cpgs = {}\n",
    "angus_non_sv_len = {}\n",
    "\n",
    "for k, v in tqdm(brahman_non_SV.items()):\n",
    "\tchrom = v.id.split(':')[0]\n",
    "\tif chrom not in brahman_non_SV_cpgs:\n",
    "\t\tbrahman_non_SV_cpgs[chrom] = 0\n",
    "\t\tbrahman_non_sv_len[chrom] = 0\n",
    "\tbrahman_non_SV_cpgs[chrom] += len(re.findall('CG', str(v.seq)))\n",
    "\tbrahman_non_sv_len[chrom] += len(v.seq) - 1\n",
    "\n",
    "for k, v in tqdm(angus_non_SV.items()):\n",
    "\tchrom = v.id.split(':')[0]\n",
    "\tif chrom not in angus_non_SV_cpgs:\n",
    "\t\tangus_non_SV_cpgs[chrom] = 0\n",
    "\t\tangus_non_sv_len[chrom] = 0\n",
    "\tangus_non_SV_cpgs[chrom] += len(re.findall('CG', str(v.seq)))\n",
    "\tangus_non_sv_len[chrom] += len(v.seq) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 1852.66it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 2195.69it/s]\n"
     ]
    }
   ],
   "source": [
    "def CpG_SV_enrichment_mwu(cpg_sv_dict,\n",
    "                      sv_len_dict,\n",
    "                      non_sv_cpg_dict,\n",
    "                      non_sv_len_dict):\n",
    "    pvalues = []\n",
    "    for chrom in tqdm(range(1,30)):\n",
    "        cpg_proportion = (cpg_sv_dict[str(chrom)] / sv_len_dict[str(chrom)])\n",
    "        non_sv_cpg_proportion = (non_sv_cpg_dict[str(chrom)] / non_sv_len_dict[str(chrom)])\n",
    "        \n",
    "        pval = mannwhitneyu(cpg_proportion, non_sv_cpg_proportion,\n",
    "                            alternative='greater').pvalue\n",
    "        pvalues.append(pval)\n",
    "    return pvalues\n",
    "\n",
    "brahman_pvalues = CpG_SV_enrichment_mwu(b_svs, b_sv_len, brahman_non_SV_cpgs, brahman_non_sv_len)\n",
    "angus_pvalues = CpG_SV_enrichment_mwu(a_svs, a_sv_len, angus_non_SV_cpgs, angus_non_sv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 221154.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012860810682802025\n",
      "0.010913646684440219\n",
      "1.1784155245870211\n",
      "MannwhitneyuResult(statistic=662.0, pvalue=8.917394796484191e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cpg_sv_dict = b_svs\n",
    "sv_len_dict = b_sv_len\n",
    "non_sv_cpg_dict = brahman_non_SV_cpgs\n",
    "non_sv_len_dict = brahman_non_sv_len\n",
    "cpg_sv_proportions = []\n",
    "non_sv_cpg_proportions = []\n",
    "for chrom in tqdm(range(1,30)):\n",
    "    cpg_proportion = (cpg_sv_dict[str(chrom)] / sv_len_dict[str(chrom)])\n",
    "    non_sv_cpg_proportion = (non_sv_cpg_dict[str(chrom)] / non_sv_len_dict[str(chrom)])\n",
    "    \n",
    "    cpg_sv_proportions.append(cpg_proportion)\n",
    "    non_sv_cpg_proportions.append(non_sv_cpg_proportion)\n",
    "\n",
    "print(np.mean(cpg_sv_proportions))\n",
    "print(np.mean(non_sv_cpg_proportions))\n",
    "print(np.mean(cpg_sv_proportions) / np.mean(non_sv_cpg_proportions))\n",
    "print(mannwhitneyu(cpg_sv_proportions, non_sv_cpg_proportions, alternative='greater'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wgbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
