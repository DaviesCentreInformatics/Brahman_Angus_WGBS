{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "from pyfaidx import Fasta\n",
    "from pybedtools import BedTool\n",
    "from scipy import stats\n",
    "from Bio import SeqIO\n",
    "import gc\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer=3\n",
    "def count_specific_kmer(seq_dict, kmer):\n",
    "    k_count = 0\n",
    "    for seq in seq_dict.values():\n",
    "        for i in range(len(seq) - len(kmer) + 1):\n",
    "            if str(seq[i:i+len(kmer)]) == kmer:\n",
    "                k_count += 1\n",
    "    return k_count\n",
    "\n",
    "def expected_specific_kmer(seq_dict, kmer):\n",
    "    big_seq = ''.join(list(seq_dict.values()))\n",
    "    expect_kmer = {k:0 for k in kmer}\n",
    "    for k in kmer:\n",
    "        expect_kmer[k] = (big_seq.count(k))\n",
    "    exp = [expect_kmer[k] for k in kmer]\n",
    "    #print(exp)\n",
    "    exp = (np.product(exp))/len(big_seq)\n",
    "    return exp\n",
    "\n",
    "def makeNonCpGWindows(not_snps, window):\n",
    "    new_df = {'chrom':[],\n",
    "          'start':[],\n",
    "          'stop':[]}\n",
    "\n",
    "    for i in tqdm(not_snps.itertuples()):\n",
    "        end = i.end - ((window * 2) + 2 - 1)\n",
    "        for j in range(i.start, end, 10):\n",
    "            start = j\n",
    "            stop = j + ((window*2) + 2)\n",
    "            new_df['chrom'].append(i.chrom)\n",
    "            new_df['start'].append(start)\n",
    "            new_df['stop'].append(stop)\n",
    "    non_cpg_windows = pd.DataFrame.from_dict(new_df)\n",
    "    return non_cpg_windows\n",
    "\n",
    "def count_kmer(seq, k):\n",
    "    k_count = {''.join(i):0 for i in itertools.product(['A','C','G','T'], repeat=k)}\n",
    "\n",
    "    for i in range(len(seq) - k + 1):\n",
    "        if ' ' in seq[i:i+k]:\n",
    "            continue\n",
    "        k_count[str(seq[i:i+k])] += 1\n",
    "    return k_count\n",
    "\n",
    "# normalise\n",
    "def normalise(kmer_dict, seq_len):\n",
    "    denominator = len(kmer_dict.keys()) * (seq_len - 2)\n",
    "    for kmer, value in kmer_dict.items():\n",
    "        kmer_dict[kmer] /= denominator\n",
    "    return kmer_dict\n",
    "\n",
    "def getFasta(df, fasta):\n",
    "    fasta_dict = {}\n",
    "    for row in df.itertuples():\n",
    "        record = fasta[str(row[1])][row[2]:row[3]]\n",
    "        if 'N' in record.seq:\n",
    "            continue\n",
    "        fasta_dict[record.fancy_name] = record.seq\n",
    "    return fasta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "big_df_dict = {}\n",
    "\n",
    "brahman = Fasta('/path/to/ref/Bos_indicus_hybrid.UOA_Brahman_1.ARS-UCD1.2.orientation.dna.toplevel.fa') ## Change to your path\n",
    "angus = Fasta('/path/to/ref/Angus.ARS-UCD1.2.orientation.fa') ## Change to your path\n",
    "\n",
    "names = ['chrom','start','stop','query_coords']\n",
    "brahman_size = {'chrom':[],\n",
    "                'len':[]}\n",
    "angus_size = {'chrom':[],\n",
    "              'len':[]}\n",
    "for i in brahman.records:\n",
    "    brahman_size['chrom'].append(i)\n",
    "    brahman_size['len'].append(len(brahman[i]))\n",
    "for i in angus.records:\n",
    "    angus_size['chrom'].append(i)\n",
    "    angus_size['len'].append(len(angus[i]))\n",
    "angus_size_df = pd.DataFrame.from_dict(angus_size)\n",
    "brahman_size_df = pd.DataFrame.from_dict(brahman_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 500 # We used 25, 50 and 500\n",
    "a2b_snps = pd.read_csv('./genome/Angus_CpG/shared_CpGs/Angus.CpGs.chrALL.to.Brahman_coords.SNP_change.bed',\n",
    "                       header=None,\n",
    "                   index_col=None,\n",
    "                   sep='\\t',\n",
    "                       names=names)\n",
    "b2a_snps = pd.read_csv('./genome/Brahman_CpG/shared_CpGs/Brahman.CpGs.chrALL.to.Angus_coords.SNP_change.bed',\n",
    "                   header=None,\n",
    "                   index_col=None,\n",
    "                   sep='\\t',\n",
    "                       names=names)\n",
    "a2b_snps['start'] = a2b_snps['start'] - window\n",
    "a2b_snps['stop'] = a2b_snps['stop'] + window\n",
    "b2a_snps['start'] = b2a_snps['start'] - window\n",
    "b2a_snps['stop'] = b2a_snps['stop'] + window\n",
    "\n",
    "a2b_snps_bed = BedTool.from_dataframe(a2b_snps)\n",
    "b2a_snps_bed = BedTool.from_dataframe(b2a_snps)\n",
    "\n",
    "a2b_not_snps_bed = a2b_snps_bed.complement(g='/Users/callummacphillamy/PhD/Reference_Genomes/common_UOA-Brahman-Angus/Brahman_oriented2_ARS/Bos_indicus_hybrid.UOA_Brahman_1.ARS-UCD1.2.orientation.dna.toplevel.chrom.sizes', L=True)\n",
    "b2a_not_snps_bed = b2a_snps_bed.complement(g='/Users/callummacphillamy/PhD/Reference_Genomes/common_UOA-Brahman-Angus/Angus/Angus.ARS-UCD1.2.orientation.chrom.sizes', L=True)\n",
    "\n",
    "a2b_not_snps = a2b_not_snps_bed.to_dataframe()\n",
    "b2a_not_snps = b2a_not_snps_bed.to_dataframe()\n",
    "\n",
    "del a2b_not_snps_bed\n",
    "del b2a_not_snps_bed\n",
    "del a2b_snps_bed\n",
    "del b2a_snps_bed\n",
    "gc.collect()\n",
    "\n",
    "a2b_not_snps = a2b_not_snps[a2b_not_snps.iloc[:,0].isin([i for i in range(1,30)])]\n",
    "b2a_not_snps = b2a_not_snps[b2a_not_snps.iloc[:,0].isin([i for i in range(1,30)])]\n",
    "\n",
    "print('Generating non CpG windows')\n",
    "a2b_not_snps_windows = makeNonCpGWindows(a2b_not_snps, window=window)\n",
    "b2a_not_snps_windows = makeNonCpGWindows(b2a_not_snps, window=window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_size = 3\n",
    "permutation_dict_1000 = {}\n",
    "for n, i in tqdm(enumerate(range(100))):\n",
    "    permutation_dict_1000[n] = {} \n",
    "    b_cpg_idx = np.arange(a2b_snps.shape[0])\n",
    "    b_cpg_idx_samp = np.random.choice(b_cpg_idx, size=1000, replace=False)\n",
    "    a2b_snps_small = a2b_snps.iloc[b_cpg_idx_samp, :]\n",
    "\n",
    "    a_cpg_idx = np.arange(b2a_snps.shape[0])\n",
    "    a_cpg_idx_samp = np.random.choice(a_cpg_idx, size=1000, replace=False)\n",
    "    b2a_snps_small = b2a_snps.iloc[a_cpg_idx_samp, :]\n",
    "\n",
    "    # Take 1000 random samples from the non-cpg windows\n",
    "    b_non_cpg_idx = np.arange(a2b_not_snps_windows.shape[0])\n",
    "    a_non_cpg_idx = np.arange(b2a_not_snps_windows.shape[0])\n",
    "\n",
    "    b_non_cpg_idx_samp = np.random.choice(b_non_cpg_idx, size=1000, replace=False)\n",
    "    a_non_cpg_idx_samp = np.random.choice(a_non_cpg_idx, size=1000, replace=False)\n",
    "\n",
    "    a2b_non_small = a2b_not_snps_windows.iloc[b_non_cpg_idx_samp, :]\n",
    "    b2a_non_small = b2a_not_snps_windows.iloc[a_non_cpg_idx_samp, :]\n",
    "\n",
    "    a2b_fa = getFasta(a2b_snps_small, brahman)\n",
    "    b2a_fa = getFasta(b2a_snps_small, angus)\n",
    "\n",
    "    a2b_not_fa = getFasta(a2b_non_small, brahman)\n",
    "    b2a_not_fa = getFasta(b2a_non_small, angus)\n",
    "\n",
    "    #a_cpg_df_dict = {''.join(i):0 for i in itertools.product(['A','C','G','T'], repeat=k)}\n",
    "    #a_non_cpg_df_dict = {''.join(i):[] for i in itertools.product(['A','C','G','T'], repeat=k)}\n",
    "    #b_cpg_df_dict = {''.join(i):[] for i in itertools.product(['A','C','G','T'], repeat=k)}\n",
    "    #b_non_cpg_df_dict = {''.join(i):[] for i in itertools.product(['A','C','G','T'], repeat=k)}\n",
    "    a2b_big_seq = ' '.join(a2b_fa.values())\n",
    "    b2a_big_seq = ' '.join(b2a_fa.values())\n",
    "    a2b_not_big_seq = ' '.join(a2b_not_fa.values())\n",
    "    b2a_not_big_seq = ' '.join(b2a_not_fa.values())\n",
    "\n",
    "    assert len(list(a2b_fa.values())[0]) == (window*2) + 2\n",
    "    assert len(list(b2a_fa.values())[0]) == (window*2) + 2\n",
    "    assert len(list(a2b_not_fa.values())[0]) == (window*2) + 2\n",
    "    assert len(list(b2a_not_fa.values())[0]) == (window*2) + 2\n",
    "\n",
    "    kmer_dict_a2b = count_kmer(a2b_big_seq, k=kmer_size)\n",
    "    kmer_dict_b2a = count_kmer(b2a_big_seq, k=kmer_size)\n",
    "\n",
    "    kmer_dict_a2b_not = count_kmer(a2b_not_big_seq, k=kmer_size)\n",
    "    kmer_dict_b2a_not = count_kmer(b2a_not_big_seq, k=kmer_size)\n",
    "\n",
    "\n",
    "    norm_a2b_fa = normalise(kmer_dict_a2b, seq_len=len(list(a2b_fa.values())[0]))\n",
    "    norm_b2a_fa = normalise(kmer_dict_b2a, seq_len=len(list(b2a_fa.values())[0]))\n",
    "\n",
    "    norm_a2b_not_fa = normalise(kmer_dict_a2b_not, seq_len=len(list(a2b_not_fa.values())[0]))\n",
    "    norm_b2a_not_fa = normalise(kmer_dict_b2a_not, seq_len=len(list(b2a_not_fa.values())[0]))\n",
    "\n",
    "\n",
    "    #for k, v in a_cpg_df_dict.items():\n",
    "    #    freq = v/(1000 * (((window*2)+2)-2))\n",
    "    #    big_df_dict[k].append(freq)\n",
    "    permutation_dict_1000[n]['A2B_SNP_kmers'] = norm_a2b_fa \n",
    "    permutation_dict_1000[n]['B2A_SNP_kmers'] = norm_b2a_fa\n",
    "    permutation_dict_1000[n]['A2B_notSNP_kmers'] = norm_a2b_not_fa\n",
    "    permutation_dict_1000[n]['B2A_notSNP_kmers'] = norm_b2a_not_fa"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
